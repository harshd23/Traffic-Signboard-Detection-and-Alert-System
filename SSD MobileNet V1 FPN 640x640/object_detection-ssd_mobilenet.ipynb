{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 10.76274824142456 seconds\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "\n",
    "# import pathlib\n",
    "# import tensorflow as tf\n",
    "# import cv2\n",
    "# import argparse\n",
    "# import tensorflow as tf\n",
    "# from object_detection.utils import config_util\n",
    "# from object_detection.protos import pipeline_pb2\n",
    "# from google.protobuf import text_format\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.utils import visualization_utils as viz_utils\n",
    "# from object_detection.builders import model_builder\n",
    "# import numpy as np\n",
    "\n",
    "# # Enable GPU dynamic memory allocation (optional)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# # PROVIDE PATH TO MODEL DIRECTORY\n",
    "# PATH_TO_MODEL_DIR = '../SSD ResNet50 V1 FPN 640x640 (RetinaNet50)/exported-models/my-model'\n",
    "\n",
    "# # PROVIDE PATH TO LABEL MAP\n",
    "# PATH_TO_LABELS = '../training_helper_directory/annotations/label_map.pbtxt'\n",
    "\n",
    "# # PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "# MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# # Load saved model and build detection function\n",
    "# print('Loading model...', end='')\n",
    "# start_time = time.time()\n",
    "\n",
    "# # LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "# detect_fn = tf.saved_model.load(PATH_TO_MODEL_DIR + \"/saved_model\")\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# # Load label map data for plotting\n",
    "# category_index = label_map_util.create_category_index_from_labelmap(\n",
    "#     PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "# # Initialize webcam capture\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # Capture frame from webcam\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         print(\"Error capturing frame!\")\n",
    "#         break\n",
    "\n",
    "#     # Resize and preprocess frame (example)\n",
    "#     image = cv2.resize(frame, (640, 640))  # Adjust to your model's input size\n",
    "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "#     # Convert to tensor and add batch dimension\n",
    "#     input_tensor = tf.convert_to_tensor(image_rgb)\n",
    "#     input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "#     # Run inference\n",
    "#     detections = detect_fn(input_tensor)\n",
    "\n",
    "#     # Parse detections and draw results\n",
    "#     num_detections = int(detections.pop('num_detections'))\n",
    "#     detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "#     detections['num_detections'] = num_detections\n",
    "#     detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "#     image_with_detections = image.copy()\n",
    "\n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#         image_with_detections,\n",
    "#         detections['detection_boxes'],\n",
    "#         detections['detection_classes'],\n",
    "#         detections['detection_scores'],\n",
    "#         category_index,\n",
    "#         use_normalized_coordinates=True,\n",
    "#         max_boxes_to_draw=100,\n",
    "#         min_score_thresh=MIN_CONF_THRESH,\n",
    "#         agnostic_mode=False\n",
    "#     )\n",
    "\n",
    "#     # Display annotated frame\n",
    "#     cv2.imshow('Object Detection', image_with_detections)\n",
    "\n",
    "#     # Exit on 'q' key press\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.utils import visualization_utils as viz_utils\n",
    "# from object_detection.builders import model_builder\n",
    "# import tensorflow as tf\n",
    "# from object_detection.utils import config_util\n",
    "# from object_detection.protos import pipeline_pb2\n",
    "# from google.protobuf import text_format\n",
    "\n",
    "# CHECKPONT_PATH = '../SSD MobileNet V1 FPN 640x640/models/ssd_mobilenet_v1_fpn_640x640'\n",
    "\n",
    "# #load pipeline config and build a detection model\n",
    "# configs = config_util.get_configs_from_pipeline_file('../SSD MobileNet V1 FPN 640x640/models/ssd_mobilenet_v1_fpn_640x640/pipeline.config')\n",
    "# detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# #Restore checkpoint\n",
    "# ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "# ckpt.restore(os.path.join(CHECKPONT_PATH, 'ckpt-26')).expect_partial()\n",
    "\n",
    "# @tf.function\n",
    "# def detect_fn(image):\n",
    "#     image, shapes = detection_model.preprocess(image)\n",
    "#     prediction_dict = detection_model.predict(image, shapes)\n",
    "#     detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "#     return detections\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# category_index = label_map_util.create_category_index_from_labelmap('../training_helper_directory/annotations/label_map.pbtxt', use_display_name=True)\n",
    "\n",
    "# #Setup Capture\n",
    "# cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     image_np = np.array(frame)\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "#     detections = detect_fn(input_tensor)\n",
    "\n",
    "#     num_detections = int(detections.pop('num_detections'))\n",
    "#     detections = {key: value[0, :num_detections].numpy()\n",
    "#                   for key, value in detections.items()}\n",
    "#     detections['num_detections'] = num_detections\n",
    "    \n",
    "#     # detection_classes should be ints.\n",
    "#     detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "#     label_id_offset = 1\n",
    "#     image_np_with_detections = image_np.copy()\n",
    "\n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#       image_np_with_detections,\n",
    "#       detections['detection_boxes'],\n",
    "#       detections['detection_classes']+label_id_offset,\n",
    "#       detections['detection_scores'],\n",
    "#       category_index,\n",
    "#       use_normalized_coordinates=True,\n",
    "#       max_boxes_to_draw=1,\n",
    "#       min_score_thresh=0.7,\n",
    "#       agnostic_mode=False)\n",
    "\n",
    "#     cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      \n",
    "#       break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "CHECKPONT_PATH = '../SSD MobileNet V1 FPN 640x640/models/ssd_mobilenet_v1_fpn_640x640'\n",
    "\n",
    "#load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file('../SSD MobileNet V1 FPN 640x640/models/ssd_mobilenet_v1_fpn_640x640/pipeline.config')\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "#Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPONT_PATH, 'ckpt-26')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap('../training_helper_directory/annotations/label_map.pbtxt', use_display_name=True)\n",
    "\n",
    "#Setup Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'],\n",
    "      detections['detection_classes']+label_id_offset,\n",
    "      detections['detection_scores'],\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=1,\n",
    "      min_score_thresh=0.7,\n",
    "      agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (1280,720)))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      \n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "traffic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
