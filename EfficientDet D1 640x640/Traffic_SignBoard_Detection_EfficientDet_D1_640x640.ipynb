{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traffic SignBoard Detection - EfficientDet D1 640x640:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. DOWNLOAD THE PRETRAINED MODELS FROM THE TENSOFLOW MODEL ZOO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "MODELS_DIR = os.path.join('pre-trained-model')\n",
        "for dir in [MODELS_DIR]:\n",
        "    if not os.path.exists(dir):\n",
        "        os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "main_directory = 'models'\n",
        "subfolder_name = 'efficientDet_D1_640x640'\n",
        "\n",
        "main_directory_path = os.path.join(os.getcwd(), main_directory)\n",
        "subfolder_path = os.path.join(main_directory_path, subfolder_name)\n",
        "\n",
        "if not os.path.exists(subfolder_path):\n",
        "    os.makedirs(subfolder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Download and extract model\n",
        "MODEL_DATE = '20200711'\n",
        "MODEL_NAME = 'efficientdet_d1_coco17_tpu-32'\n",
        "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
        "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
        "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
        "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
        "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
        "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
        "if not os.path.exists(PATH_TO_CKPT):\n",
        "    print('Downloading model. This may take a while... ', end='')\n",
        "    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
        "    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
        "    tar_file.extractall(MODELS_DIR)\n",
        "    tar_file.close()\n",
        "    os.remove(PATH_TO_MODEL_TAR)\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SETUP PATHS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORKSPACE_PATH = '../training_helper_directory'\n",
        "SCRIPT_PATH = WORKSPACE_PATH + '/scripts'\n",
        "ANNOTATION_PATH = WORKSPACE_PATH + '/annotations'\n",
        "\n",
        "IMAGE_PATH = '../Dataset/\"PASCAL VOC Format Dataset\"'\n",
        "\n",
        "CUSTOM_MODEL_NAME = '/efficientDet_D1_640x640'\n",
        "MODEL_PATH = './models' + CUSTOM_MODEL_NAME\n",
        "\n",
        "PRETRAINED_PATH = './pre-trained-model/' + MODEL_NAME\n",
        "CONFIG_PATH = MODEL_PATH + '/pipeline.config'\n",
        "\n",
        "EXPORT_PATH = '../exported-models/my-model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CREATE TF RECORDS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU2lVZfzyuar",
        "outputId": "878d88c4-7b15-44ac-e289-79355b5b9566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: ../training_helper_directory/annotations/train.record\n",
            "Successfully created the TFRecord file: ../training_helper_directory/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "# Create train data:\n",
        "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
        "\n",
        "# Create test data:\n",
        "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. COPY MODEL CONFIG FILE TO TRANING FOLDER:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "SOURCE_PATH = \"D:\\Traffic SignBoard Recognition using Deep Learning\\EfficientDet D1 640x640\\pre-trained-model\\efficientdet_d1_coco17_tpu-32\\pipeline.config\"\n",
        "DESTINATION_PATH = \"D:\\Traffic SignBoard Recognition using Deep Learning\\EfficientDet D1 640x640\\models\\efficientDet_D1_640x640\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        1 file(s) copied.\n"
          ]
        }
      ],
      "source": [
        "!copy \"{SOURCE_PATH}\" \"{DESTINATION_PATH}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. UPDATING CONFIG FOR TRANSFER LEARNING:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     keep_aspect_ratio_resizer {\n",
              "       min_dimension: 640\n",
              "       max_dimension: 640\n",
              "       pad_to_max_dimension: true\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_efficientnet-b1_bifpn_keras\"\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         truncated_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.029999999329447746\n",
              "         }\n",
              "       }\n",
              "       activation: SWISH\n",
              "       batch_norm {\n",
              "         decay: 0.9900000095367432\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "       force_use_bias: true\n",
              "     }\n",
              "     bifpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       num_iterations: 4\n",
              "       num_filters: 88\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 1.0\n",
              "       x_scale: 1.0\n",
              "       height_scale: 1.0\n",
              "       width_scale: 1.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: SWISH\n",
              "         batch_norm {\n",
              "           decay: 0.9900000095367432\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "         force_use_bias: true\n",
              "       }\n",
              "       depth: 88\n",
              "       num_layers_before_predictor: 3\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 3\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.5\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 1.5\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              "   add_background_class: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_scale_crop_and_pad_to_square {\n",
              "     output_size: 640\n",
              "     scale_min: 0.10000000149011612\n",
              "     scale_max: 2.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 300000\n",
              "         warmup_learning_rate: 0.0010000000474974513\n",
              "         warmup_steps: 2500\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 300000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " use_bfloat16: true\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false\n",
              " batch_size: 1,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
              " }}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = 56 \n",
        "\n",
        "pipeline_config.train_config.batch_size = 1\n",
        "pipeline_config.train_config.num_steps = 1500\n",
        "\n",
        "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_PATH + '/checkpoint/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\" \n",
        "\n",
        "pipeline_config.train_input_reader.label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH+ '/train.record'] \n",
        "\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. TRAIN THE MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Traffic SignBoard Recognition using Deep Learning\\\\EfficientDet D1 640x640'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNVwlSCq9pr1",
        "outputId": "b7d397d0-5254-4ca2-e7df-c4bbe5f6bd88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 14:14:58.786438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-07 14:14:59.619173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2116 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0307 14:15:04.404982 24184 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0307 14:15:04.404982 24184 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0307 14:15:04.404982 24184 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I0307 14:15:04.419990 24184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0307 14:15:04.419990 24184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0307 14:15:04.419990 24184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0307 14:15:04.419990 24184 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.451452 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.454458 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.456457 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.457458 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.457458 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.466988 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.473496 24184 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0307 14:15:04.473496 24184 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.473496 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.473496 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.489130 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:04.489130 24184 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0307 14:15:08.429961 24184 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0307 14:15:08.432958 24184 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0307 14:15:08.805874 24184 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0307 14:15:08.805874 24184 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0307 14:15:09.115117 24184 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0307 14:15:09.115117 24184 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0307 14:15:11.836742 24184 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0307 14:15:11.836742 24184 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0307 14:15:12.237471 24184 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0307 14:15:12.237471 24184 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0307 14:15:14.700426 24184 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0307 14:15:14.700426 24184 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0307 14:15:14.930469 24184 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0307 14:15:15.026824 24184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0307 14:15:17.605629 24184 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['../training_helper_directory/annotations/train.record']\n",
            "I0307 14:15:17.634933 24184 dataset_builder.py:162] Reading unweighted datasets: ['../training_helper_directory/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['../training_helper_directory/annotations/train.record']\n",
            "I0307 14:15:17.634933 24184 dataset_builder.py:79] Reading record datasets for input file: ['../training_helper_directory/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0307 14:15:17.634933 24184 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0307 14:15:17.634933 24184 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0307 14:15:17.639942 24184 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0307 14:15:17.691635 24184 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0307 14:15:25.035617 24184 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0307 14:15:30.154803 24184 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2024-03-07 14:15:34.823302: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4915200 exceeds 10% of free system memory.\n",
            "2024-03-07 14:15:34.823677: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4915200 exceeds 10% of free system memory.\n",
            "2024-03-07 14:15:34.824175: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4915200 exceeds 10% of free system memory.\n",
            "2024-03-07 14:15:34.824913: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4915200 exceeds 10% of free system memory.\n",
            "2024-03-07 14:15:34.825703: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4915200 exceeds 10% of free system memory.\n",
            "d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "I0307 14:15:41.364724 17932 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0307 14:15:58.508734 17440 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-03-07 14:16:15.198741: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907\n",
            "2024-03-07 14:16:30.422499: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:16:30.423039: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:16:30.542600: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:16:30.543084: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:16:31.155900: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:16:31.156663: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0307 14:16:44.410339  4268 deprecation.py:554] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0307 14:16:47.213067  4268 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0307 14:16:53.238898  4268 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "I0307 14:17:00.031066  9116 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0307 14:17:06.197805  9116 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "I0307 14:17:11.572669 24364 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0307 14:17:17.679170 24364 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "I0307 14:17:23.865357 18928 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W0307 14:17:30.940571 18928 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "2024-03-07 14:18:04.037667: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:18:04.038160: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:18:04.059217: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-07 14:18:04.059645: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "INFO:tensorflow:Step 100 per-step time 1.507s\n",
            "I0307 14:19:14.632914 24184 model_lib_v2.py:705] Step 100 per-step time 1.507s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.7158253,\n",
            " 'Loss/localization_loss': 0.0266355,\n",
            " 'Loss/regularization_loss': 0.029534668,\n",
            " 'Loss/total_loss': 1.7719955,\n",
            " 'learning_rate': 0.00416}\n",
            "I0307 14:19:14.633847 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.7158253,\n",
            " 'Loss/localization_loss': 0.0266355,\n",
            " 'Loss/regularization_loss': 0.029534668,\n",
            " 'Loss/total_loss': 1.7719955,\n",
            " 'learning_rate': 0.00416}\n",
            "INFO:tensorflow:Step 200 per-step time 0.633s\n",
            "I0307 14:20:17.895800 24184 model_lib_v2.py:705] Step 200 per-step time 0.633s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.8200556,\n",
            " 'Loss/localization_loss': 0.025186317,\n",
            " 'Loss/regularization_loss': 0.029528463,\n",
            " 'Loss/total_loss': 1.8747704,\n",
            " 'learning_rate': 0.0073200003}\n",
            "I0307 14:20:17.895800 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.8200556,\n",
            " 'Loss/localization_loss': 0.025186317,\n",
            " 'Loss/regularization_loss': 0.029528463,\n",
            " 'Loss/total_loss': 1.8747704,\n",
            " 'learning_rate': 0.0073200003}\n",
            "INFO:tensorflow:Step 300 per-step time 0.632s\n",
            "I0307 14:21:21.125115 24184 model_lib_v2.py:705] Step 300 per-step time 0.632s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.7291927,\n",
            " 'Loss/localization_loss': 0.013738021,\n",
            " 'Loss/regularization_loss': 0.029530838,\n",
            " 'Loss/total_loss': 1.7724617,\n",
            " 'learning_rate': 0.010480001}\n",
            "I0307 14:21:21.125115 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.7291927,\n",
            " 'Loss/localization_loss': 0.013738021,\n",
            " 'Loss/regularization_loss': 0.029530838,\n",
            " 'Loss/total_loss': 1.7724617,\n",
            " 'learning_rate': 0.010480001}\n",
            "INFO:tensorflow:Step 400 per-step time 0.617s\n",
            "I0307 14:22:22.815180 24184 model_lib_v2.py:705] Step 400 per-step time 0.617s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.786841,\n",
            " 'Loss/localization_loss': 0.009009065,\n",
            " 'Loss/regularization_loss': 0.029533783,\n",
            " 'Loss/total_loss': 1.8253839,\n",
            " 'learning_rate': 0.0136400005}\n",
            "I0307 14:22:22.815180 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.786841,\n",
            " 'Loss/localization_loss': 0.009009065,\n",
            " 'Loss/regularization_loss': 0.029533783,\n",
            " 'Loss/total_loss': 1.8253839,\n",
            " 'learning_rate': 0.0136400005}\n",
            "INFO:tensorflow:Step 500 per-step time 0.625s\n",
            "I0307 14:23:25.347720 24184 model_lib_v2.py:705] Step 500 per-step time 0.625s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.5144085,\n",
            " 'Loss/localization_loss': 0.0097261695,\n",
            " 'Loss/regularization_loss': 0.0295497,\n",
            " 'Loss/total_loss': 1.5536844,\n",
            " 'learning_rate': 0.016800001}\n",
            "I0307 14:23:25.347720 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.5144085,\n",
            " 'Loss/localization_loss': 0.0097261695,\n",
            " 'Loss/regularization_loss': 0.0295497,\n",
            " 'Loss/total_loss': 1.5536844,\n",
            " 'learning_rate': 0.016800001}\n",
            "INFO:tensorflow:Step 600 per-step time 0.597s\n",
            "I0307 14:24:25.042195 24184 model_lib_v2.py:705] Step 600 per-step time 0.597s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.4288799,\n",
            " 'Loss/localization_loss': 0.047719754,\n",
            " 'Loss/regularization_loss': 0.030468425,\n",
            " 'Loss/total_loss': 1.507068,\n",
            " 'learning_rate': 0.019960001}\n",
            "I0307 14:24:25.042195 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.4288799,\n",
            " 'Loss/localization_loss': 0.047719754,\n",
            " 'Loss/regularization_loss': 0.030468425,\n",
            " 'Loss/total_loss': 1.507068,\n",
            " 'learning_rate': 0.019960001}\n",
            "INFO:tensorflow:Step 700 per-step time 0.604s\n",
            "I0307 14:25:25.409203 24184 model_lib_v2.py:705] Step 700 per-step time 0.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1206926,\n",
            " 'Loss/localization_loss': 0.012646468,\n",
            " 'Loss/regularization_loss': 0.030899046,\n",
            " 'Loss/total_loss': 1.1642381,\n",
            " 'learning_rate': 0.023120001}\n",
            "I0307 14:25:25.410203 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.1206926,\n",
            " 'Loss/localization_loss': 0.012646468,\n",
            " 'Loss/regularization_loss': 0.030899046,\n",
            " 'Loss/total_loss': 1.1642381,\n",
            " 'learning_rate': 0.023120001}\n",
            "INFO:tensorflow:Step 800 per-step time 0.606s\n",
            "I0307 14:26:26.024405 24184 model_lib_v2.py:705] Step 800 per-step time 0.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1047692,\n",
            " 'Loss/localization_loss': 0.010928031,\n",
            " 'Loss/regularization_loss': 0.03174993,\n",
            " 'Loss/total_loss': 1.1474472,\n",
            " 'learning_rate': 0.02628}\n",
            "I0307 14:26:26.024405 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.1047692,\n",
            " 'Loss/localization_loss': 0.010928031,\n",
            " 'Loss/regularization_loss': 0.03174993,\n",
            " 'Loss/total_loss': 1.1474472,\n",
            " 'learning_rate': 0.02628}\n",
            "INFO:tensorflow:Step 900 per-step time 0.612s\n",
            "I0307 14:27:27.264990 24184 model_lib_v2.py:705] Step 900 per-step time 0.612s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1622572,\n",
            " 'Loss/localization_loss': 0.01742347,\n",
            " 'Loss/regularization_loss': 0.031967666,\n",
            " 'Loss/total_loss': 1.2116483,\n",
            " 'learning_rate': 0.02944}\n",
            "I0307 14:27:27.264990 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.1622572,\n",
            " 'Loss/localization_loss': 0.01742347,\n",
            " 'Loss/regularization_loss': 0.031967666,\n",
            " 'Loss/total_loss': 1.2116483,\n",
            " 'learning_rate': 0.02944}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.628s\n",
            "I0307 14:28:30.060467 24184 model_lib_v2.py:705] Step 1000 per-step time 0.628s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.83822834,\n",
            " 'Loss/localization_loss': 0.01431606,\n",
            " 'Loss/regularization_loss': 0.032480814,\n",
            " 'Loss/total_loss': 0.88502526,\n",
            " 'learning_rate': 0.0326}\n",
            "I0307 14:28:30.060467 24184 model_lib_v2.py:708] {'Loss/classification_loss': 0.83822834,\n",
            " 'Loss/localization_loss': 0.01431606,\n",
            " 'Loss/regularization_loss': 0.032480814,\n",
            " 'Loss/total_loss': 0.88502526,\n",
            " 'learning_rate': 0.0326}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.613s\n",
            "I0307 14:29:31.335393 24184 model_lib_v2.py:705] Step 1100 per-step time 0.613s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0271004,\n",
            " 'Loss/localization_loss': 0.005100409,\n",
            " 'Loss/regularization_loss': 0.03285279,\n",
            " 'Loss/total_loss': 1.0650536,\n",
            " 'learning_rate': 0.03576}\n",
            "I0307 14:29:31.335393 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.0271004,\n",
            " 'Loss/localization_loss': 0.005100409,\n",
            " 'Loss/regularization_loss': 0.03285279,\n",
            " 'Loss/total_loss': 1.0650536,\n",
            " 'learning_rate': 0.03576}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.604s\n",
            "I0307 14:30:31.781696 24184 model_lib_v2.py:705] Step 1200 per-step time 0.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1828465,\n",
            " 'Loss/localization_loss': 0.0141630145,\n",
            " 'Loss/regularization_loss': 0.033039715,\n",
            " 'Loss/total_loss': 1.2300493,\n",
            " 'learning_rate': 0.03892}\n",
            "I0307 14:30:31.781696 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.1828465,\n",
            " 'Loss/localization_loss': 0.0141630145,\n",
            " 'Loss/regularization_loss': 0.033039715,\n",
            " 'Loss/total_loss': 1.2300493,\n",
            " 'learning_rate': 0.03892}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.604s\n",
            "I0307 14:31:32.225939 24184 model_lib_v2.py:705] Step 1300 per-step time 0.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.91558367,\n",
            " 'Loss/localization_loss': 0.0020945366,\n",
            " 'Loss/regularization_loss': 0.03304247,\n",
            " 'Loss/total_loss': 0.95072067,\n",
            " 'learning_rate': 0.04208}\n",
            "I0307 14:31:32.225939 24184 model_lib_v2.py:708] {'Loss/classification_loss': 0.91558367,\n",
            " 'Loss/localization_loss': 0.0020945366,\n",
            " 'Loss/regularization_loss': 0.03304247,\n",
            " 'Loss/total_loss': 0.95072067,\n",
            " 'learning_rate': 0.04208}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.649s\n",
            "I0307 14:32:37.169867 24184 model_lib_v2.py:705] Step 1400 per-step time 0.649s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1684412,\n",
            " 'Loss/localization_loss': 0.0119941095,\n",
            " 'Loss/regularization_loss': 0.033522654,\n",
            " 'Loss/total_loss': 1.2139579,\n",
            " 'learning_rate': 0.04524}\n",
            "I0307 14:32:37.169867 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.1684412,\n",
            " 'Loss/localization_loss': 0.0119941095,\n",
            " 'Loss/regularization_loss': 0.033522654,\n",
            " 'Loss/total_loss': 1.2139579,\n",
            " 'learning_rate': 0.04524}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.681s\n",
            "I0307 14:33:45.241171 24184 model_lib_v2.py:705] Step 1500 per-step time 0.681s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0111594,\n",
            " 'Loss/localization_loss': 0.019343352,\n",
            " 'Loss/regularization_loss': 0.033585038,\n",
            " 'Loss/total_loss': 1.0640879,\n",
            " 'learning_rate': 0.0484}\n",
            "I0307 14:33:45.241171 24184 model_lib_v2.py:708] {'Loss/classification_loss': 1.0111594,\n",
            " 'Loss/localization_loss': 0.019343352,\n",
            " 'Loss/regularization_loss': 0.033585038,\n",
            " 'Loss/total_loss': 1.0640879,\n",
            " 'learning_rate': 0.0484}\n"
          ]
        }
      ],
      "source": [
        "!python {SCRIPT_PATH + '/model_main_tf2.py'} --model_dir={MODEL_PATH} --pipeline_config_path={MODEL_PATH + '/pipeline.config'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeI2URnR9zhw",
        "outputId": "6065d907-bd15-4353-e1be-33c71d6702f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 14:33:59.154167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-07 14:33:59.653829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2137 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "I0307 14:33:59.727354  4272 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0307 14:33:59.727354  4272 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0307 14:33:59.727354  4272 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0307 14:33:59.727354  4272 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0307 14:33:59.748215  4272 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0307 14:33:59.748215  4272 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0307 14:33:59.866332  4272 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0307 14:33:59.866332  4272 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0307 14:34:00.074555  4272 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0307 14:34:00.074555  4272 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0307 14:34:00.282917  4272 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0307 14:34:00.282917  4272 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0307 14:34:00.560695  4272 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0307 14:34:00.560695  4272 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0307 14:34:00.838395  4272 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0307 14:34:00.838395  4272 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0307 14:34:01.192639  4272 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0307 14:34:01.192639  4272 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0307 14:34:01.338511  4272 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0307 14:34:01.366842  4272 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0307 14:34:04.692684  4272 deprecation.py:623] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "I0307 14:34:08.831662  4272 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0307 14:34:25.700133  4272 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0307 14:34:38.624223  4272 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001D43C7A27C0>, because it is not built.\n",
            "W0307 14:34:47.735360  4272 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001D43C7A27C0>, because it is not built.\n",
            "W0307 14:35:39.078849  4272 save.py:233] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: exported-models\\my-model\\saved_model\\assets\n",
            "I0307 14:36:09.455125  4272 builder_impl.py:779] Assets written to: exported-models\\my-model\\saved_model\\assets\n",
            "INFO:tensorflow:Writing pipeline config file to exported-models\\my-model\\pipeline.config\n",
            "I0307 14:36:11.426549  4272 config_util.py:253] Writing pipeline config file to exported-models\\my-model\\pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!python {SCRIPT_PATH + '/exporter_main_v2.py'} --input_type image_tensor --pipeline_config_path {CONFIG_PATH} --trained_checkpoint_dir {MODEL_PATH + '/' } --output_directory exported-models\\my-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0313 12:49:16.922596 20692 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0313 12:49:16.922596 20692 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0313 12:49:16.922596 20692 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0313 12:49:16.922596 20692 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0313 12:49:16.922596 20692 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2024-03-13 12:49:16.925115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-13 12:49:17.467589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2137 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "I0313 12:49:19.562602 20692 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0313 12:49:19.562602 20692 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0313 12:49:19.562602 20692 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0313 12:49:19.565178 20692 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0313 12:49:19.583379 20692 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0313 12:49:19.583379 20692 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0313 12:49:19.688447 20692 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0313 12:49:19.688447 20692 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0313 12:49:19.867079 20692 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0313 12:49:19.868079 20692 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0313 12:49:20.049353 20692 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0313 12:49:20.049353 20692 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0313 12:49:20.293715 20692 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0313 12:49:20.293715 20692 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0313 12:49:20.521830 20692 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0313 12:49:20.521830 20692 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0313 12:49:20.811526 20692 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0313 12:49:20.811526 20692 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0313 12:49:20.926554 20692 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0313 12:49:20.949433 20692 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:Reading unweighted datasets: ['../training_helper_directory/annotations/test.record']\n",
            "I0313 12:49:21.126007 20692 dataset_builder.py:162] Reading unweighted datasets: ['../training_helper_directory/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['../training_helper_directory/annotations/test.record']\n",
            "I0313 12:49:21.127007 20692 dataset_builder.py:79] Reading record datasets for input file: ['../training_helper_directory/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0313 12:49:21.127007 20692 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0313 12:49:21.127007 20692 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0313 12:49:21.128277 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0313 12:49:21.147470 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0313 12:49:24.518210 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0313 12:49:25.546346 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at ./models/efficientDet_D1_640x640\n",
            "I0313 12:49:27.682624 20692 checkpoint_utils.py:136] Waiting for new checkpoint at ./models/efficientDet_D1_640x640\n",
            "INFO:tensorflow:Found new checkpoint at ./models/efficientDet_D1_640x640\\ckpt-2\n",
            "I0313 12:49:27.683624 20692 checkpoint_utils.py:145] Found new checkpoint at ./models/efficientDet_D1_640x640\\ckpt-2\n",
            "d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "I0313 12:49:35.772850 20692 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0313 12:49:53.952859 20692 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-03-13 12:50:07.980511: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907\n",
            "2024-03-13 12:50:11.047297: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-13 12:50:11.047652: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-13 12:50:11.120093: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-13 12:50:11.120647: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-13 12:50:11.438196: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-03-13 12:50:11.438621: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0313 12:50:12.142897 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0313 12:50:12.151896 20692 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0313 12:50:12.260886 20692 deprecation.py:350] From d:\\Anaconda3\\envs\\traffic\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0313 12:50:34.621561 20692 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0313 12:50:55.012432 20692 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0313 12:51:15.425243 20692 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0313 12:51:35.985782 20692 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0313 12:51:56.673137 20692 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0313 12:52:17.577558 20692 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Performing evaluation on 665 images.\n",
            "I0313 12:52:30.856140 20692 coco_evaluation.py:293] Performing evaluation on 665 images.\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0313 12:52:30.857136 20692 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0313 12:52:30.893136 20692 coco_tools.py:138] DONE (t=0.04s)\n",
            "INFO:tensorflow:Eval metrics at step 1000\n",
            "I0313 12:52:34.373218 20692 model_lib_v2.py:1015] Eval metrics at step 1000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.001636\n",
            "I0313 12:52:34.384217 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.001636\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.004417\n",
            "I0313 12:52:34.386218 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.004417\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001259\n",
            "I0313 12:52:34.388224 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001259\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
            "I0313 12:52:34.389219 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
            "I0313 12:52:34.391218 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.001676\n",
            "I0313 12:52:34.392220 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.001676\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.042586\n",
            "I0313 12:52:34.394223 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.042586\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.078967\n",
            "I0313 12:52:34.395222 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.078967\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.078967\n",
            "I0313 12:52:34.397220 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.078967\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
            "I0313 12:52:34.398219 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
            "I0313 12:52:34.400217 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.080092\n",
            "I0313 12:52:34.402217 20692 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.080092\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 1.239093\n",
            "I0313 12:52:34.404216 20692 model_lib_v2.py:1018] \t+ Loss/localization_loss: 1.239093\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 4262.560547\n",
            "I0313 12:52:34.405216 20692 model_lib_v2.py:1018] \t+ Loss/classification_loss: 4262.560547\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.032481\n",
            "I0313 12:52:34.406215 20692 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.032481\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 4263.832520\n",
            "I0313 12:52:34.408223 20692 model_lib_v2.py:1018] \t+ Loss/total_loss: 4263.832520\n",
            "INFO:tensorflow:Waiting for new checkpoint at ./models/efficientDet_D1_640x640\n",
            "I0313 12:54:27.697362 20692 checkpoint_utils.py:136] Waiting for new checkpoint at ./models/efficientDet_D1_640x640\n",
            "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
            "I0313 13:54:27.082112 20692 checkpoint_utils.py:199] Timed-out waiting for a checkpoint.\n"
          ]
        }
      ],
      "source": [
        "!python {SCRIPT_PATH + '/model_main_tf2.py'} --model_dir={MODEL_PATH} --pipeline_config_path={MODEL_PATH + '/pipeline.config'} --checkpoint_dir={MODEL_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIIKwpxtGAhK"
      },
      "source": [
        "Inferencing My Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "spZJ4ms3FqRT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 26.787789583206177 seconds\n",
            "Running inference for D:/Traffic SignBoard Recognition using Deep Learning/Dataset/PASCAL VOC Format Dataset/valid/all_motor_vehicle_prohibited-21_jpg.rf.087d485a4c160bc08f5c56df6ff3e1d6.jpg... Done\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = 'D:/Traffic SignBoard Recognition using Deep Learning/Dataset/PASCAL VOC Format Dataset/valid/all_motor_vehicle_prohibited-21_jpg.rf.087d485a4c160bc08f5c56df6ff3e1d6.jpg'\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = './exported-models/my-model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=2,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2.imshow('test', image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !tensorboard --logdir D:\"/Traffic SignBoard Recognition using Deep Learning\"/\"EfficientDet D0 512x512\"/models/efficientDet_D0_512x512 --host localhost --port 6009"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "traffic",
      "language": "python",
      "name": "traffic"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
